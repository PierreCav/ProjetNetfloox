{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports dans un autre fichier\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averageRating</th>\n",
       "      <th>startYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.3</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.9</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.1</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>8.4</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>8.7</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       averageRating  startYear  runtimeMinutes\n",
       "0                9.3     2004.0            45.0\n",
       "1                6.3     2019.0            41.0\n",
       "2                6.5     2019.0            29.0\n",
       "3                5.9     2019.0            37.0\n",
       "4                8.1     2004.0            43.0\n",
       "...              ...        ...             ...\n",
       "49995            9.0     2008.0            42.0\n",
       "49996            7.3     2008.0            40.0\n",
       "49997            8.4     2019.0           112.0\n",
       "49998            7.3     2008.0            49.0\n",
       "49999            8.7     1960.0           150.0\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('BDD_URL.env')\n",
    "BDD_URL = os.environ['BDD_URL']\n",
    "engine = create_engine(BDD_URL)\n",
    "\n",
    "SQL = 'SELECT \"averageRating\", \"startYear\", \"runtimeMinutes\" from principal.title_basics join principal.title_ratings on principal.title_basics.\"tconst\" = principal.title_ratings.\"tconst\"  limit 50000;'\n",
    "df = pd.read_sql(SQL, engine)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13972/1074364059.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score training: 1.7204828560535173\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/laamh/Documents/Travail/ProjetNetFloox/ProjetNetfloox/exercice12_01.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/laamh/Documents/Travail/ProjetNetFloox/ProjetNetfloox/exercice12_01.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m y_pred \u001b[39m=\u001b[39m searchCV\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/laamh/Documents/Travail/ProjetNetFloox/ProjetNetfloox/exercice12_01.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mScore training:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m-\u001b[39msearchCV\u001b[39m.\u001b[39mbest_score_)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/laamh/Documents/Travail/ProjetNetFloox/ProjetNetfloox/exercice12_01.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mScore recall test:\u001b[39m\u001b[39m\"\u001b[39m, recall_score(y_test, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/laamh/Documents/Travail/ProjetNetFloox/ProjetNetfloox/exercice12_01.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLe modèle de ML utilisé c\u001b[39m\u001b[39m'\u001b[39m\u001b[39mest le\u001b[39m\u001b[39m\"\u001b[39m, searchCV\u001b[39m.\u001b[39mbest_params_[\u001b[39m'\u001b[39m\u001b[39mmodelisation\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Travail/ProjetNetFloox/ProjetNetfloox/env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Travail/ProjetNetFloox/ProjetNetfloox/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2351\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   2184\u001b[0m     {\n\u001b[1;32m   2185\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2210\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2211\u001b[0m ):\n\u001b[1;32m   2212\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   2213\u001b[0m \n\u001b[1;32m   2214\u001b[0m \u001b[39m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[39m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   2350\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2351\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   2352\u001b[0m         y_true,\n\u001b[1;32m   2353\u001b[0m         y_pred,\n\u001b[1;32m   2354\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   2355\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   2356\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   2357\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   2358\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   2359\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   2360\u001b[0m     )\n\u001b[1;32m   2361\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/Documents/Travail/ProjetNetFloox/ProjetNetfloox/env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    188\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Travail/ProjetNetFloox/ProjetNetfloox/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1755\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m \n\u001b[1;32m   1594\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m _check_zero_division(zero_division)\n\u001b[0;32m-> 1755\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1757\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Travail/ProjetNetFloox/ProjetNetfloox/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1527\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1525\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1527\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1528\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/Documents/Travail/ProjetNetFloox/ProjetNetfloox/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:105\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    108\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(y_true, y_pred)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "for column in [\"averageRating\", \"startYear\", \"runtimeMinutes\"]:\n",
    "    df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "# Target\n",
    "y = df['averageRating']\n",
    "# Features\n",
    "X = df[['startYear','runtimeMinutes']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Séparation de type des données\n",
    "preparation = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('data_num', RobustScaler(), [\"startYear\", \"runtimeMinutes\"])\n",
    "])\n",
    "\n",
    "# Pipeline\n",
    "pipel = Pipeline(steps=[\n",
    "    ('scaling', preparation),\n",
    "    ('modelisation', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'modelisation': [DecisionTreeRegressor()]\n",
    "}\n",
    "scorer = {'mean_squared_error': mean_squared_error}\n",
    "\n",
    "searchCV = GridSearchCV(pipel, params, scoring='neg_mean_squared_error', refit=True)\n",
    "\n",
    "searchCV.fit(X_train, y_train)\n",
    "y_pred = searchCV.predict(X_test)\n",
    "print(\"Score training:\", -searchCV.best_score_)\n",
    "print(\"Score recall test:\", recall_score(y_test, y_pred, average=None))\n",
    "print(\"Le modèle de ML utilisé c'est le\", searchCV.best_params_['modelisation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
