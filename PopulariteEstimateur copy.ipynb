{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des données\n",
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# Graphics\n",
    "import seaborn as sns ; sns.set()\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('BDD_URL.env')\n",
    "BDD_URL = os.environ['BDD_URL']\n",
    "engine = create_engine(BDD_URL)\n",
    "\n",
    "SQL_filtre= \"\"\"\n",
    "SET search_path to principal;\n",
    "SELECT *\n",
    "from \"filmview\"\n",
    "where 'Comedy' = ANY(string_to_array(\"genres\", ','))\n",
    "limit 10000;\n",
    "\"\"\"\n",
    "SQL= \"\"\"\n",
    "SET search_path to principal;\n",
    "SELECT *\n",
    "from \"filmview\"\n",
    "where \"runtimeMinutes\" Is NOT null and \"titleType\" = 'movie' and \"averageRating\" is NOT NULL and \"genres\" is NOT NULL and \"startYear\" is NOT NULL and \"isAdult\" is NOT NULL\n",
    "limit 70000;\n",
    "\"\"\"\n",
    "df = pd.read_sql(SQL, engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BooleanToText (df):\n",
    "    return df.apply(lambda x: 'True' if x == 1 else 'False')\n",
    "def DateToCategory (df):\n",
    "    \n",
    "    df.fillna(df.mean(), inplace=True) # a valider\n",
    "    \n",
    "    bins = list(range(1800, 2056, 5))  # Intervalles de 5\n",
    "    labels = [f\"Datebetween{start}and{start+4}\" for start in range(1800, 2051, 5)]\n",
    "\n",
    "    return pd.cut(df, bins=bins, labels=labels, right=False)\n",
    "def RuntimeToCategory (df):\n",
    "    \n",
    "    df.fillna(df.mean(), inplace=True) # a valider\n",
    "    \n",
    "    bins = list(range(0, 615, 15))  # Intervalles de 10h\n",
    "    labels = [f\"runtime_Between{start}and{start+15}\" for start in range(0, 600, 15)]\n",
    "\n",
    "    return pd.cut(df, bins=bins, labels=labels, right=False) #qcut \n",
    "def RatingToCategory (df):\n",
    "    \n",
    "    df.fillna(df.mean(), inplace=True) # a valider\n",
    "    \n",
    "    bins = list(range(0, 12, 2))  \n",
    "    labels = ['*','**','***','****','*****']\n",
    "\n",
    "    return pd.cut(df, bins=bins, labels=labels, right=False)\n",
    "def listTostr (df):\n",
    "    return df.apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Resurrection of Jake the Snake movie Datebetween2015and2019 runtime_Between90and105 Biography Documentary Sport ADULT_False director_Steve_Yu editor_Dylan_Frymyer editor_Neely_Coe self_Louie_Benson editor_Nathan_Mowery self_Adam_Copeland cinematographer_Nicholas_Leone self_Joe_Case self_Steve_Austin '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature'] = df['primaryTitle'] + ' '\n",
    "df['feature'] += df['titleType'] + ' '\n",
    "df['feature'] += DateToCategory(df['startYear']).astype(str) + ' '\n",
    "df['feature'] += RuntimeToCategory (df['runtimeMinutes']).astype(str)+ ' '\n",
    "df['feature'] += df['genres'].str.replace(',', ' ') + ' '\n",
    "\n",
    "df['feature'] += 'ADULT_'+BooleanToText (df['isAdult']).astype(str)+' '\n",
    "\n",
    "df['feature'] += listTostr (df['Cate&names']).astype(str)+' '\n",
    "df['feature'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des caractéristiques et de la cible\n",
    "X = df.drop(columns=[\"averageRating\"])\n",
    "y = df[\"averageRating\"]\n",
    "\n",
    "# Séparation des données d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)#, random_state=42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des colonnes numériques, textuelles et de description\n",
    "numeric_features = ['startYear', 'runtimeMinutes']\n",
    "boolean_features = 'isAdult'\n",
    "text_features = 'titleType'\n",
    "title = 'primaryTitle'#['primaryTitle''titleType', 'directors', 'writers']\n",
    "genre = 'genres'\n",
    "description_feature = 'feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;description&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;tf_idf&#x27;,\n",
       "                                                  TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                  decode_error=&#x27;ignore&#x27;,\n",
       "                                                                  max_features=1000))]),\n",
       "                                 &#x27;feature&#x27;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;description&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;tf_idf&#x27;,\n",
       "                                                  TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                  decode_error=&#x27;ignore&#x27;,\n",
       "                                                                  max_features=1000))]),\n",
       "                                 &#x27;feature&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">description</label><div class=\"sk-toggleable__content\"><pre>feature</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, decode_error=&#x27;ignore&#x27;, max_features=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('description',\n",
       "                                 Pipeline(steps=[('tf_idf',\n",
       "                                                  TfidfVectorizer(analyzer='char_wb',\n",
       "                                                                  decode_error='ignore',\n",
       "                                                                  max_features=1000))]),\n",
       "                                 'feature')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création des transformers pour les colonnes numériques, booléennes, textuelles et de description\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "boolean_transformer = FunctionTransformer(lambda x: x.astype(bool).values.reshape(-1, 1)) \n",
    "\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "Vect_transformer = Pipeline([\n",
    "    # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), \n",
    "    ('vect', CountVectorizer(decode_error='ignore', analyzer='char_wb')) #max_features=1000, analyzer=\"word\"\n",
    "])\n",
    "tfidf_transformer = Pipeline([\n",
    "    # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), \n",
    "    ('tf_idf', TfidfVectorizer(decode_error='ignore', analyzer='char_wb', max_features=1000)) #max_features=1000\n",
    "])\n",
    "# Création d'un ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # ('num', numeric_transformer, numeric_features),\n",
    "        # ('bool', boolean_transformer, boolean_features),\n",
    "        # ('text', Vect_transformer, text_features),\n",
    "        # ('title', tfidf_transformer, title),\n",
    "        # ('genre', tfidf_transformer, genre),\n",
    "        ('description', tfidf_transformer, description_feature)\n",
    "    ])\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des pipelines pour chaque modèle\n",
    "pipelines = {\n",
    "    'Linear Regression': Pipeline([('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
    "    'Ridge Regression': Pipeline([('preprocessor', preprocessor), ('regressor', Ridge())]),\n",
    "    'Lasso Regression': Pipeline([('preprocessor', preprocessor), ('regressor', Lasso())]),\n",
    "    'ElasticNet': Pipeline([('preprocessor', preprocessor), ('regressor', ElasticNet())]),\n",
    "    'SVR': Pipeline([('preprocessor', preprocessor), ('regressor', SVR())]),\n",
    "    'Random Forest Regression': Pipeline([('preprocessor', preprocessor), ('regressor', RandomForestRegressor())]),\n",
    "    'Gradient Boosting Regression': Pipeline([('preprocessor', preprocessor), ('regressor', GradientBoostingRegressor())]),\n",
    "    \n",
    "}\n",
    "\n",
    "# Paramètres pour GridSearchCV pour chaque modèle\n",
    "parameters = {\n",
    "    'Linear Regression': {'regressor__fit_intercept': [True,False]},\n",
    "    'Ridge Regression': {'regressor__alpha': [0.1, 2.0,5, 10.0]},\n",
    "    'Lasso Regression': {'regressor__alpha': [0.1, 2.0,5, 10.0]},\n",
    "    'ElasticNet': {'regressor__alpha': [0.1, 2.0, 10.0], 'regressor__l1_ratio': [0.1, 0.5, 0.9]},\n",
    "    'SVR': {'regressor__kernel': ['linear', 'rbf'], 'regressor__C': [0.1, 1.0, 10.0]},\n",
    "    'Random Forest Regression': {'regressor__n_estimators': [150,200], 'regressor__max_depth': [50,100]},# None, \n",
    "    'Gradient Boosting Regression': {'regressor__n_estimators': [150,200], 'regressor__max_depth': [50, 100]},\n",
    "    \n",
    "}\n",
    "\n",
    "# Scoring : RMSE, R2 et MAE\n",
    "scoring = {'RMSE': 'neg_root_mean_squared_error',\n",
    "           'R2': 'r2',\n",
    "           'MAE': 'neg_mean_absolute_error'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grid(X_train, y_train, pipeline, parameters, cv=5):\n",
    "  # Scoring\n",
    "  #multi_scoring = {mean_squared_error,r2_score}\n",
    "    \n",
    "    \n",
    "  # Grid search\n",
    "  grid = GridSearchCV(pipeline, parameters,  scoring=scoring, refit='RMSE', cv=cv, n_jobs =-1, verbose = 0, error_score='raise')\n",
    "\n",
    "  # Fit\n",
    "  grid.fit(X_train, y_train)\n",
    "\n",
    "  # Scores and results\n",
    "  best_score = grid.best_score_.round(4)\n",
    "  best_params = grid.best_params_\n",
    "  training_time = grid.cv_results_['mean_fit_time'].mean().round(4)\n",
    "\n",
    "  # Output\n",
    "  return({\n",
    "      'best_score': best_score,\n",
    "      'best_params': best_params,\n",
    "      'training_time': training_time,\n",
    "      'fitted_model': grid.best_estimator_\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficheResults (grid):\n",
    "    model_name = grid['fitted_model'].named_steps['regressor'].__class__.__name__\n",
    "    print(f\"{model_name} training time: {grid['training_time']}\")\n",
    "    print(f\"Best {model_name} parameters: {grid['best_params']}\")\n",
    "    print(f\"Best {model_name} score: {-grid['best_score']}\")\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..............Linear Regression..............................\n",
      "LinearRegression training time: 13.8559\n",
      "Best LinearRegression parameters: {'regressor__fit_intercept': True}\n",
      "Best LinearRegression score: 1.2228\n",
      "Linear Regression RMSE: 1.2275\n",
      "\n",
      "..............Ridge Regression..............................\n",
      "Ridge training time: 15.5629\n",
      "Best Ridge parameters: {'regressor__alpha': 0.1}\n",
      "Best Ridge score: 1.2221\n",
      "Ridge Regression RMSE: 1.2266\n",
      "\n",
      "..............Lasso Regression..............................\n",
      "Lasso training time: 11.1664\n",
      "Best Lasso parameters: {'regressor__alpha': 0.1}\n",
      "Best Lasso score: 1.2972\n",
      "Lasso Regression RMSE: 1.303\n",
      "\n",
      "..............ElasticNet..............................\n",
      "ElasticNet training time: 12.9288\n",
      "Best ElasticNet parameters: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.1}\n",
      "Best ElasticNet score: 1.2971\n",
      "ElasticNet RMSE: 1.303\n",
      "\n",
      "..............SVR..............................\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Boucle sur les modèles pour ajuster avec GridSearchCV\n",
    "models = {}\n",
    "\n",
    "# Boucle sur les modèles pour ajuster avec GridSearchCV et évaluation\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(f\"\\n..............{model_name}..............................\")\n",
    "    grid_search = Grid(X_train, y_train, pipeline, parameters[model_name], cv=5)\n",
    "    afficheResults (grid_search)\n",
    "    \n",
    "    best_model = grid_search['fitted_model']\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    Rmse = round(math.sqrt(mse), 4)\n",
    "    models[model_name] = [best_model,Rmse]\n",
    "    print(f\"{model_name} RMSE: {Rmse}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Boucle sur les modèles pour ajuster avec GridSearchCV\\nresults = {}\\n\\n# Boucle sur les modèles pour ajuster avec GridSearchCV et évaluation\\nfor model_name, pipeline in pipelines.items():\\n    print(f\"Training {model_name}...\")\\n    grid_search = GridSearchCV(pipeline, parameters[model_name],  scoring=scoring, refit=\\'RMSE\\', cv=5, n_jobs =-1, verbose = 1)\\n    grid_search.fit(X_train, y_train)\\n    best_model = grid_search.best_estimator_\\n    y_pred = best_model.predict(X_test)\\n    mse = root_mean_squared_error(y_test, y_pred)\\n    results[model_name] = mse\\n    print(f\"Best parameters: {grid_search.best_params_}\")\\n    print(f\"Best {model_name} score: {-grid_search.best_score_}\")\\n    print(f\"{model_name} MSE: {mse}\")\\n    print()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Boucle sur les modèles pour ajuster avec GridSearchCV\n",
    "results = {}\n",
    "\n",
    "# Boucle sur les modèles pour ajuster avec GridSearchCV et évaluation\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    grid_search = GridSearchCV(pipeline, parameters[model_name],  scoring=scoring, refit='RMSE', cv=5, n_jobs =-1, verbose = 1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = root_mean_squared_error(y_test, y_pred)\n",
    "    results[model_name] = mse\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best {model_name} score: {-grid_search.best_score_}\")\n",
    "    print(f\"{model_name} MSE: {mse}\")\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Evaluation des modèles sur les données de test\\nprint(\"\\nComparaison des performances des modèles sur les données de test:\")\\nfor model_name, mse in results.items():\\n    print(f\"{model_name}: MSE = {mse}\")\\n    \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Evaluation des modèles sur les données de test\n",
    "print(\"\\nComparaison des performances des modèles sur les données de test:\")\n",
    "for model_name, mse in results.items():\n",
    "    print(f\"{model_name}: MSE = {mse}\")\n",
    "    \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
